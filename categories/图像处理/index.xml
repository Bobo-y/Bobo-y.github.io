<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>图像处理 on Lin Yang&#39;s Blog</title>
    <link>https://yl305237731.github.io/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/</link>
    <description>Recent content in 图像处理 on Lin Yang&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 20 Dec 2018 15:44:06 +0800</lastBuildDate>
    
	<atom:link href="https://yl305237731.github.io/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>模版匹配之相关匹配</title>
      <link>https://yl305237731.github.io/post/pipei1/</link>
      <pubDate>Thu, 20 Dec 2018 15:44:06 +0800</pubDate>
      
      <guid>https://yl305237731.github.io/post/pipei1/</guid>
      <description>模板匹配 最近准备把学过的一些知识整理写成博客，加深印象。 模板匹配是一种最原始、最基本的模式识别方法，研究某一特定对象物的图案位于图像的什么地方，进而识别对象物，这就是一个匹配问题。它是图像处理中最基本、最常用的匹配方法。模板匹配具有自身的局限性，主要表现在它只能进行平行移动，若原图像中的匹配目标发生旋转或大小变化，该算法无效。
普通的模板匹配方法属于暴力搜索法，通过将模板图像不断在搜索图上移动，计算模板与模板覆盖区域子图像的相似度，显而易见，时间复杂度特别大。 相关法 相关法即计算模板与图像子区域的相关系数，相关系数也能反映出两张图片的相似度 计算公式： 对于模板 T(m,n),搜索图像 S(W,H),模板覆盖被搜索图的那块区域叫子图 $S_{ij}$, i,j 为子图在被搜索图中左上角的坐标, 模板高h,宽w, 1 =&amp;lt; i =&amp;lt; H-h, 1 =&amp;lt; j =&amp;lt; W-w, $$ R(i,j) = \frac{\sum {m=1}^{M}\sum{n=1}^{N}S_{ij}(m,n)* T(m,n)}{\sqrt{\sum {m=1}^{M}\sum{n=1}^{N}[S_{ij}(m,n)]^{2} \sum {m=1}^{M}\sum{n=1}^{N}[T(m,n)]^{2}}} $$
实验结果 1. 这是当时的一个作业 搜索图：
模板一： 模板2： 匹配结果如下： 两个模板都定位到同一目标，人眼可看出模板2和场景中定位出的目标匹配，模板1和定位出的并不是同一个，但是是最大的相似度，故匹配出
2 模板lena: very good.
代码 from PIL import Image import matplotlib.image as mpimg import matplotlib.pyplot as plt import numpy as np class templateMatch: x = 0 y = 0 flag = False def rgb2gray(self,src): if 3 == len(src.</description>
    </item>
    
    <item>
      <title>基于Keras图像相似度计算孪生网络</title>
      <link>https://yl305237731.github.io/post/keras_simi/</link>
      <pubDate>Mon, 12 Nov 2018 16:32:32 +0800</pubDate>
      
      <guid>https://yl305237731.github.io/post/keras_simi/</guid>
      <description>import keras from keras.layers import Input,Dense,Conv2D from keras.layers import MaxPooling2D,Flatten,Convolution2D from keras.models import Model import os import numpy as np from PIL import Image from keras.optimizers import SGD from scipy import misc root_path = os.getcwd() train_names = [&#39;bear&#39;,&#39;blackswan&#39;,&#39;bus&#39;,&#39;camel&#39;,&#39;car&#39;,&#39;cows&#39;,&#39;dance&#39;,&#39;dog&#39;,&#39;hike&#39;,&#39;hoc&#39;,&#39;kite&#39;,&#39;lucia&#39;,&#39;mallerd&#39;,&#39;pigs&#39;,&#39;soapbox&#39;,&#39;stro&#39;,&#39;surf&#39;,&#39;swing&#39;,&#39;train&#39;,&#39;walking&#39;] test_names = [&#39;boat&#39;,&#39;dance-jump&#39;,&#39;drift-turn&#39;,&#39;elephant&#39;,&#39;libby&#39;] def load_data(seq_names,data_number,seq_len): #生成图片对 print(&#39;loading data.....&#39;) frame_num = 51 train_data1 = [] train_data2 = [] train_lab = [] count = 0 while count &amp;lt; data_number: count = count + 1 pos_neg = np.</description>
    </item>
    
    <item>
      <title>图像相似度之PSNR与SSIM小结</title>
      <link>https://yl305237731.github.io/post/psnr/</link>
      <pubDate>Wed, 03 Oct 2018 16:55:08 +0800</pubDate>
      
      <guid>https://yl305237731.github.io/post/psnr/</guid>
      <description>###PSNR（Peak Signal to Noise Ratio）：峰值信噪比 使用局部均值误差来判断差异，对于两个H*W*C的图像，I1,I2 其中n为采样值的比特数，比如 0-255的灰度图，n为8. PSNR算法简单，检查的速度也很快。但是其呈现的差异值有时候和人的主观感受不成比例。
####SSIM（structural similarity）：结构相似性 \mu_x , \mu_y 分别为x,y的均值，\sigma_x , \sigmay ,\sigma{xy}分别为x,y的方差以及协方差。c1与c2用来维持稳定的常数。
参考：opencv 中文教程</description>
    </item>
    
    <item>
      <title>图像联通区域标记</title>
      <link>https://yl305237731.github.io/post/coonectregion/</link>
      <pubDate>Fri, 21 Sep 2018 17:01:55 +0800</pubDate>
      
      <guid>https://yl305237731.github.io/post/coonectregion/</guid>
      <description>###由于最近做实验用到二值图像连通区域（八连通）标记，刚开始的时候为了验证算法有效性，用了递归的方法（太慢了，而且图像一大就容易栈溢出），最后查看了opencv和MATLAB的实现，做个记录。（为了简单说明，以下说明已四连通为例）
扫描法连通区域标记： 例：对于二值图像、四连通
第一次遍历： 1.建立一个和图像大小一样的矩阵保存结果，原图记为im,结果矩阵记为mask,mask各元素值可初始化为0. 从上到下，从左到右扫描原图像，变量Mark记录当前赋值 2.若当前访问像素坐标（i,j）且im[i,j]不为0，访问mask[i-1]j和mask[i,j-1]（若未越界）,二者若均为0，Mark++，赋值给当前坐标对应的mask. 若其中一个为0，将非0值赋值给mask[i][j]。 若均非0且相等，将mask[i][j]标记为同一类，若不等将二者最小值赋予mask[i][j],同时将二者合并为同一类（并查集）。
第二次遍历： 根据并查集的内容对区域赋值。
def countRegion(img): [high,width] = np.shape(img) mask = np.zeros_like(img) mark = 0 union = {} for i in range (high): for j in range(width): if i==0 and j==0: if img[i][j]==255: mark=mark+1 mask[i][j]=mark union[mark]=mark if i==0 and j!=0: if img[i][j]==255: left = mask[i][j-1] if left!=0: mask[i][j]=left else: mark = mark +1 mask[i][j]=mark union[mark]=mark if j==0 and i!=0: if img[i][j]==255: up = mask[i-1][j] up_right = mask[i-1][j+1] if up==0 and up_right==0: mark = mark+1 mask[i][j]=mark union[mark]=mark if up==0 and up_right!</description>
    </item>
    
  </channel>
</rss>