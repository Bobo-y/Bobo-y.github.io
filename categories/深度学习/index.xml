<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>深度学习 on 扬帆起航</title>
    <link>/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 深度学习 on 扬帆起航</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 24 Aug 2019 21:42:13 +0800</lastBuildDate>
    
	<atom:link href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>CycleGAN论文阅读总结及实现</title>
      <link>/post/cyclegan/</link>
      <pubDate>Sat, 24 Aug 2019 21:42:13 +0800</pubDate>
      
      <guid>/post/cyclegan/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); 在cyclegan之前，对于两个域的图像进行转化，比如图像风格转换，它们的训练集图像都是成对的.而cyclegan则解决了训练图像</description>
    </item>
    
    <item>
      <title>基于vgg16的半监督视频单目标分割网络</title>
      <link>/post/%E5%9F%BA%E4%BA%8Evgg%E7%9A%84%E8%A7%86%E9%A2%91%E7%9B%AE%E6%A0%87%E5%88%86%E5%89%B2/</link>
      <pubDate>Sat, 24 Aug 2019 00:03:12 +0800</pubDate>
      
      <guid>/post/%E5%9F%BA%E4%BA%8Evgg%E7%9A%84%E8%A7%86%E9%A2%91%E7%9B%AE%E6%A0%87%E5%88%86%E5%89%B2/</guid>
      <description>.img-wrap{ border: 1px } img{ float: left; width: 25%; height: 160; } one-shot 半监督视频单目标分割 网络实现 采用keras实现，网络结构如下。 类似于unet，但没有unet那么多的参数。 # coding=utf-8 from keras</description>
    </item>
    
    <item>
      <title>（译）你的神经网络不工作的37个可能原因</title>
      <link>/post/37reasonsforyournetnotwork/</link>
      <pubDate>Wed, 07 Aug 2019 11:29:13 +0800</pubDate>
      
      <guid>/post/37reasonsforyournetnotwork/</guid>
      <description>神经网络的训练是一个复杂的问题，很多时候会遇见即使拿到了别人的代码也训练不出来，无法复现。 以下是37个训练网络的建议英文原文： 1.最基本的措</description>
    </item>
    
    <item>
      <title>基于yolo_v3的水印检测</title>
      <link>/post/yovo-keras/</link>
      <pubDate>Sun, 21 Jul 2019 21:25:20 +0800</pubDate>
      
      <guid>/post/yovo-keras/</guid>
      <description>背景 近年来版权意识的提高，在使用别人图片的时候（尤其是商业领域），需要检测图片是否有别的公司的水印（ 主要针对人眼可见的水印，除去数字加密等水</description>
    </item>
    
    <item>
      <title>Hr_net阅读笔记</title>
      <link>/post/hr_net/</link>
      <pubDate>Sat, 13 Apr 2019 14:52:14 +0800</pubDate>
      
      <guid>/post/hr_net/</guid>
      <description>HRNet 是中科大与微软亚洲研究院今年发表的关于人体姿态估计的论文中提出的网络结构。 我不是做姿态估计的，主要是HRNet的结构对于需要跨层特征融合以</description>
    </item>
    
    <item>
      <title>Keras多标签分类网络实现</title>
      <link>/post/keras_duofenlei/</link>
      <pubDate>Fri, 29 Mar 2019 15:07:11 +0800</pubDate>
      
      <guid>/post/keras_duofenlei/</guid>
      <description>简谈多分类与多标签分类 简单的说，输入一张图片进行分类： * 这张图片里面的物体（通常认为只有一个物体）属于某一个类，各个类别之间的概率是竞争关系</description>
    </item>
    
    <item>
      <title>python下mnist数据集转化为图片</title>
      <link>/post/mnist2img/</link>
      <pubDate>Sat, 22 Dec 2018 15:37:02 +0800</pubDate>
      
      <guid>/post/mnist2img/</guid>
      <description>环境：tensorflow 代码如下 from tensorflow.examples.tutorials.mnist import input_data from scipy import misc import numpy as np import os mnist = input_data.read_data_sets(&#39;MNIST_data/&#39;,one_hot=True) result_path =&#39;mnist_data\\train&#39; def onehot2id(labels): return list(labels).index(1) if not os.path.exists(result_path): os.mkdir(result_path) labels_txt = open(&#39;train_labs.txt&#39;,&#39;w&#39;) for i in range(len(mnist.train.images)): img_vec = mnist.train.images[i,:] img_arr = np.reshape(img_vec,[28,28]) img_lab = mnist.train.labels[i,:] img_id = onehot2id(img_lab) labels_txt.write(str(i)+&#39; &#39;+str(img_id)+&#39;\n&#39;) img_path = os.path.join(result_path,str(i)+&#39;.png&#39;) misc.imsave(img_path,img_arr) 以</description>
    </item>
    
    <item>
      <title>基于Keras图像相似度计算孪生网络</title>
      <link>/post/keras_simi/</link>
      <pubDate>Mon, 12 Nov 2018 16:32:32 +0800</pubDate>
      
      <guid>/post/keras_simi/</guid>
      <description>import keras from keras.layers import Input,Dense,Conv2D from keras.layers import MaxPooling2D,Flatten,Convolution2D from keras.models import Model import os import numpy as np from PIL import Image from keras.optimizers import SGD from scipy import misc root_path = os.getcwd() train_names = [&#39;bear&#39;,&#39;blackswan&#39;,&#39;bus&#39;,&#39;camel&#39;,&#39;car&#39;,&#39;cows&#39;,&#39;dance&#39;,&#39;dog&#39;,&#39;hike&#39;,&#39;hoc&#39;,&#39;kite&#39;,&#39;lucia&#39;,&#39;mallerd&#39;,&#39;pigs&#39;,&#39;soapbox&#39;,&#39;stro&#39;,&#39;surf&#39;,&#39;swing&#39;,&#39;train&#39;,&#39;walking&#39;] test_names = [&#39;boat&#39;,&#39;dance-jump&#39;,&#39;drift-turn&#39;,&#39;elephant&#39;,&#39;libby&#39;] def load_data(seq_names,data_number,seq_len): #生成图片对 print(&#39;loading data.....&#39;) frame_num = 51 train_data1 = [] train_data2 = [] train_lab = [] count = 0 while count &amp;lt; data_number:</description>
    </item>
    
    <item>
      <title>Keras 猫狗二分类</title>
      <link>/post/kdog_cat/</link>
      <pubDate>Sun, 11 Nov 2018 16:36:27 +0800</pubDate>
      
      <guid>/post/kdog_cat/</guid>
      <description>import keras from keras.models import Sequential from keras.layers import Dense,MaxPooling2D,Input,Flatten,Convolution2D,Dropout,GlobalAveragePooling2D from keras.optimizers import SGD from keras.callbacks import TensorBoard,ModelCheckpoint from PIL import Image import os import numpy as np from scipy import misc root_path = os.getcwd() def load_data(): tran_imags = [] labels = [] seq_names = [&#39;cat&#39;,&#39;dog&#39;] for seq_name in seq_names: frames = sorted(os.listdir(os.path.join(root_path,&#39;data&#39;,&#39;train_data&#39;, seq_name))) for frame in frames: imgs = [os.path.join(root_path, &#39;data&#39;, &#39;train_data&#39;, seq_name, frame)] imgs = np.array(Image.open(imgs[0])) tran_imags.append(imgs) if</description>
    </item>
    
  </channel>
</rss>