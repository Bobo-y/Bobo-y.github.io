<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>深度学习 on 扬帆起航</title>
    <link>/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 深度学习 on 扬帆起航</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 18 Dec 2019 11:59:07 +0800</lastBuildDate>
    
	<atom:link href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Squeeze-and-Excitation Networks</title>
      <link>/post/se-net/</link>
      <pubDate>Wed, 18 Dec 2019 11:59:07 +0800</pubDate>
      
      <guid>/post/se-net/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); Squeeze-and-Excitation Networks（SENet)是CVPR2018公布的一种全新的图像识别结构，它通过对特征通道间的相关性进行建模，把重要的特征进</description>
    </item>
    
    <item>
      <title>动手搭建神经网络之:简单联合分割、检测网络</title>
      <link>/post/how_to_built_a_simple_maskrcnn/</link>
      <pubDate>Mon, 28 Oct 2019 23:58:27 +0800</pubDate>
      
      <guid>/post/how_to_built_a_simple_maskrcnn/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); coursera deeplearning.ai目标检测课后实践，构建一个简化版单目标yolo目标检测并添加前景对象分割分支 网络结构 MASK-Rc</description>
    </item>
    
    <item>
      <title>GRU小结</title>
      <link>/post/gru%E5%B0%8F%E7%BB%93/</link>
      <pubDate>Mon, 07 Oct 2019 22:05:27 +0800</pubDate>
      
      <guid>/post/gru%E5%B0%8F%E7%BB%93/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); GRU(Gated Recurrent Unit)即门控循环单元，是LSTM的变体. GRU保留了LSTM对梯度消失问题的抗力，但内部更简单. LSTM有：输入门，遗忘门</description>
    </item>
    
    <item>
      <title>Edge_gan总结</title>
      <link>/post/edge_gan/</link>
      <pubDate>Thu, 19 Sep 2019 23:32:10 +0800</pubDate>
      
      <guid>/post/edge_gan/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); 最近刚好在做分割，顺手玩玩用GAN做边缘检测. 本意是想在BSDS轮廓分割数据集上做，同时验证针对样本极不平衡的损失函数挑选问题，简</description>
    </item>
    
    <item>
      <title>从RNN到LSTM小记</title>
      <link>/post/lstm/</link>
      <pubDate>Fri, 13 Sep 2019 19:51:54 +0800</pubDate>
      
      <guid>/post/lstm/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); 记录自己对LSTM结构的理解，以及结合keras在实现LSTM模型时数据的输入数据等的处理。 1.SimpleRNN 对于多层感知机网络而言，是假设每个输</description>
    </item>
    
    <item>
      <title>CRNN笔记以及数字检测识别实践</title>
      <link>/post/crnn%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%BB%A5%E5%8F%8A%E6%95%B0%E5%AD%97%E6%A3%80%E6%B5%8B%E8%AF%86%E5%88%AB%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sun, 08 Sep 2019 16:07:07 +0800</pubDate>
      
      <guid>/post/crnn%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%BB%A5%E5%8F%8A%E6%95%B0%E5%AD%97%E6%A3%80%E6%B5%8B%E8%AF%86%E5%88%AB%E5%AE%9E%E7%8E%B0/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); 主流的OCR识别分为两个部分:先检测出文字区域再识别文字。检测可采用通用的目标检测方法以及针对于文本检测的网络,识别主要是CRNN</description>
    </item>
    
    <item>
      <title>East:An Efficient and Accurate Scene Text Detector阅读及应用</title>
      <link>/post/east%E5%8F%8A%E5%BA%94%E7%94%A8/</link>
      <pubDate>Wed, 28 Aug 2019 00:03:07 +0800</pubDate>
      
      <guid>/post/east%E5%8F%8A%E5%BA%94%E7%94%A8/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); East是旷视科技2017年发表的论文,针对于场景文本检测。与较早的rcnn,ctpn不同之处个人认为主要在于East以目标检测来</description>
    </item>
    
    <item>
      <title>CycleGAN论文阅读总结及实现</title>
      <link>/post/cyclegan/</link>
      <pubDate>Sat, 24 Aug 2019 21:42:13 +0800</pubDate>
      
      <guid>/post/cyclegan/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); 在cyclegan之前，对于两个域的图像进行转化，比如图像风格转换，它们的训练集图像都是成对的.而cyclegan则解决了训练图像</description>
    </item>
    
    <item>
      <title>基于vgg16的半监督视频单目标分割网络</title>
      <link>/post/%E5%9F%BA%E4%BA%8Evgg%E7%9A%84%E8%A7%86%E9%A2%91%E7%9B%AE%E6%A0%87%E5%88%86%E5%89%B2/</link>
      <pubDate>Sat, 24 Aug 2019 00:03:12 +0800</pubDate>
      
      <guid>/post/%E5%9F%BA%E4%BA%8Evgg%E7%9A%84%E8%A7%86%E9%A2%91%E7%9B%AE%E6%A0%87%E5%88%86%E5%89%B2/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); .img-wrap{ border: 1px } img{ float: left; width: 25%; height: 160; } one-shot 半监督视频单目标分割 网络实现 采用keras实现，网络结构如下。 类似于unet，但没有unet那么多的参数</description>
    </item>
    
    <item>
      <title>（译）你的神经网络不工作的37个可能原因</title>
      <link>/post/37reasonsforyournetnotwork/</link>
      <pubDate>Wed, 07 Aug 2019 11:29:13 +0800</pubDate>
      
      <guid>/post/37reasonsforyournetnotwork/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); 神经网络的训练是一个复杂的问题，很多时候会遇见即使拿到了别人的代码也训练不出来，无法复现。 以下是37个训练网络的建议英文原文： 1.</description>
    </item>
    
    <item>
      <title>基于yolo_v3的水印检测</title>
      <link>/post/yovo-keras/</link>
      <pubDate>Sun, 21 Jul 2019 21:25:20 +0800</pubDate>
      
      <guid>/post/yovo-keras/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); 背景 近年来版权意识的提高，在使用别人图片的时候（尤其是商业领域），需要检测图片是否有别的公司的水印（ 主要针对人眼可见的水印，除去数</description>
    </item>
    
    <item>
      <title>Hr_net阅读笔记</title>
      <link>/post/hr_net/</link>
      <pubDate>Sat, 13 Apr 2019 14:52:14 +0800</pubDate>
      
      <guid>/post/hr_net/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); HRNet 是中科大与微软亚洲研究院今年发表的关于人体姿态估计的论文中提出的网络结构。 我不是做姿态估计的，主要是HRNet的结构对于需要跨层</description>
    </item>
    
    <item>
      <title>Keras多标签分类网络实现</title>
      <link>/post/keras_duofenlei/</link>
      <pubDate>Fri, 29 Mar 2019 15:07:11 +0800</pubDate>
      
      <guid>/post/keras_duofenlei/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); 简谈多分类与多标签分类 简单的说，输入一张图片进行分类： * 这张图片里面的物体（通常认为只有一个物体）属于某一个类，各个类别之间的概率</description>
    </item>
    
    <item>
      <title>python下mnist数据集转化为图片</title>
      <link>/post/mnist2img/</link>
      <pubDate>Sat, 22 Dec 2018 15:37:02 +0800</pubDate>
      
      <guid>/post/mnist2img/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); 环境：tensorflow 代码如下 from tensorflow.examples.tutorials.mnist import input_data from scipy import misc import numpy as np import os mnist = input_data.read_data_sets(&#39;MNIST_data/&#39;,one_hot=True) result_path =&#39;mnist_data\\train&#39; def onehot2id(labels): return list(labels).index(1) if not os.path.exists(result_path): os.mkdir(result_path) labels_txt = open(&#39;train_labs.txt&#39;,&#39;w&#39;) for i in range(len(mnist.train.images)): img_vec = mnist.train.images[i,:] img_arr = np.reshape(img_vec,[28,28]) img_lab = mnist.train.labels[i,:] img_id = onehot2id(img_lab) labels_txt.write(str(i)+&#39; &#39;+str(img_id)+&#39;\n&#39;)</description>
    </item>
    
    <item>
      <title>基于Keras图像相似度计算孪生网络</title>
      <link>/post/keras_simi/</link>
      <pubDate>Mon, 12 Nov 2018 16:32:32 +0800</pubDate>
      
      <guid>/post/keras_simi/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); import keras from keras.layers import Input,Dense,Conv2D from keras.layers import MaxPooling2D,Flatten,Convolution2D from keras.models import Model import os import numpy as np from PIL import Image from keras.optimizers import SGD from scipy import misc root_path = os.getcwd() train_names = [&#39;bear&#39;,&#39;blackswan&#39;,&#39;bus&#39;,&#39;camel&#39;,&#39;car&#39;,&#39;cows&#39;,&#39;dance&#39;,&#39;dog&#39;,&#39;hike&#39;,&#39;hoc&#39;,&#39;kite&#39;,&#39;lucia&#39;,&#39;mallerd&#39;,&#39;pigs&#39;,&#39;soapbox&#39;,&#39;stro&#39;,&#39;surf&#39;,&#39;swing&#39;,&#39;train&#39;,&#39;walking&#39;] test_names = [&#39;boat&#39;,&#39;dance-jump&#39;,&#39;drift-turn&#39;,&#39;elephant&#39;,&#39;libby&#39;] def load_data(seq_names,data_number,seq_len): #生成图片对 print(&#39;loading data.....&#39;) frame_num = 51 train_data1 = [] train_data2 = [] train_lab = [] count =</description>
    </item>
    
    <item>
      <title>Keras 猫狗二分类</title>
      <link>/post/kdog_cat/</link>
      <pubDate>Sun, 11 Nov 2018 16:36:27 +0800</pubDate>
      
      <guid>/post/kdog_cat/</guid>
      <description>(adsbygoogle = window.adsbygoogle || []).push({}); import keras from keras.models import Sequential from keras.layers import Dense,MaxPooling2D,Input,Flatten,Convolution2D,Dropout,GlobalAveragePooling2D from keras.optimizers import SGD from keras.callbacks import TensorBoard,ModelCheckpoint from PIL import Image import os import numpy as np from scipy import misc root_path = os.getcwd() def load_data(): tran_imags = [] labels = [] seq_names = [&#39;cat&#39;,&#39;dog&#39;] for seq_name in seq_names: frames = sorted(os.listdir(os.path.join(root_path,&#39;data&#39;,&#39;train_data&#39;, seq_name))) for frame in frames: imgs = [os.path.join(root_path, &#39;data&#39;, &#39;train_data&#39;, seq_name, frame)]</description>
    </item>
    
  </channel>
</rss>