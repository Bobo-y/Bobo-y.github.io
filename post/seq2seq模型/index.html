<!DOCTYPE html>
<html class="no-js" lang="zh-cn">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Seq2Seq模型: 从理论到实践 - fly away, chase dream</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<script type="text/javascript" src="/js/jquery.min.js"></script>
	
	<meta name="description" content="">
	<meta name="generator" content="Hugo 0.57.2" />
	<meta property="og:title" content="Seq2Seq模型: 从理论到实践" />
<meta property="og:description" content="理论结合实践是学习的最佳方式, 本文代码来源于pytorch-seq2seq Seq2Seq 模型 对于序列预测, RNN及其变种LSTM、GRU等无疑是最好的解" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/seq2seq%E6%A8%A1%E5%9E%8B/" />
<meta property="article:published_time" content="2020-05-01T17:31:29+08:00" />
<meta property="article:modified_time" content="2020-05-01T17:31:29+08:00" />

	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">	
	<link rel="stylesheet" type="text/css" href="/css/highlight.css">
	
	
	<link rel="stylesheet" href="/css/share.min.css">
	<script src="/js/social-share.min.js"></script>
	<script src="/js/qrcode.js"></script>
	
	<link rel="stylesheet" href="/css/custom.css">
	<link rel="shortcut icon" href="/favicon.ico">
		
	
    
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-3547912397637948",
      enable_page_level_ads: true
    });
  </script>

	
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/" title="fly away, chase dream" rel="home">
			<div class="logo__title">fly away, chase dream</div>			
				<div class="logo__tagline">ML、CV、Image process...</div> 
			</a>
			
			<div class="float_right"><div class="social-share"></div>
  <br/></div>
			
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/about/">about</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/">blog</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/leetcode/">leetcode</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/life/">life📚</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/links/">links</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/wiki/">wiki</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="container">
      <a href="https://www.vultr.com/?ref=8356511-4F"><img src="https://www.vultr.com/media/banners/banner_728x90.png" width="800" height="90"></a>
		</div>
		<hr/>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Seq2Seq模型: 从理论到实践</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2020-05-01T17:31:29">2020-05-01</time>
</div>

<div class="meta__item-categories meta__item">
	<svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
	<span class="meta__text"><a class="meta__link" href="/categories/%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86" rel="category">自然语言处理</a></span>
</div>
</div>
		</header>
<div class="content post__content clearfix">
			

<p><em>理论结合实践是学习的最佳方式, 本文代码来源于<a href="http://localhost:8889/notebooks/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb">pytorch-seq2seq</a></em></p>

<h2 id="seq2seq-模型">Seq2Seq 模型</h2>

<p>对于序列预测, RNN及其变种LSTM、GRU等无疑是最好的解决模型. 对于单个RNN、LSTM模型而言, 模型在每个时间步进行提取特征并输出(也可以在某个时间步不显示的输出), 但是其输出序列的长度最大等于输入序列的长度. 在现实任务中, 比如语言翻译, 源语句和目标语句长度不一样, 单个LSTM就无法完成由输入到输出的映射.</p>

<p>既然单个LSTM无法完成, 考虑用两个. 用一个LSTM来编码输入序列得到固定大小的表达向量, 再用另一个LSTM来解码该向量. Seq2Seq 的典型模型为 Encoder-Decoder 模型, 下图为语言翻译的Encoder-Decoder 模型.</p>

<div align="center"><img src="/img/seq2seq/2.jpg" width="600" height="500"></div>

<p>在编码器的每一个时间步，根据当前单词的词向量$e(x_t)$以及上一个时间步的hidden状态.</p>

<p>$$ h_t = EncoderRNN( e(x _t), h _{t -1})$$</p>

<p>在编码器对整个语句编码完成后, 得到 context vector, 解码器将 context vector作为输入. 在解码器的每一个时间步, 输入为目标词的词向量以及解码器上一个时间步的状态.</p>

<p>$$s_t = DecoderRNN(d(y_t), s _{t-1})$$</p>

<p>解码器需要将当前时间步的hidden状态对应到实际的单词, 通过使用全连接层, 输出为词汇表的大小, 每一个位置对应属于一个词的概率.</p>

<h2 id="深入代码">深入代码</h2>

<p>编码器构建</p>

<pre><code class="language-python">class Encoder(nn.Module):
    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):
        super().__init__()
        # input_dim: 源词汇表的大小

        # hidden units LSTM 每一个门的神经元个数
        self.hid_dim = hid_dim
        # LSTM 层数
        self.n_layers = n_layers
        # Embedding 初始化时指定词汇表的大小和需要得到的词向量大小
        # 前向传播时输入数据为该语句中每个单词在词汇表中的index,会根据index去查找
        self.embedding = nn.Embedding(input_dim, emb_dim)

        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)

        self.dropout = nn.Dropout(dropout)

    def forward(self, src):
        # src shape为 [len src, batch_size]
        # src 中每列为一个句子, 值为该句子中每个单词在词汇表中的index, 由于句子拼接成数组要求维度一样, 所以当batch size内句子长短不一样时,
        # 将短句子全部填充为最长句子的长度, 填充时以指定的填充单词index填充

        # 进行embedding, 得到固定大小的embedded 向量, shape=[len src, batch_size, emb dim]
        src = self.embedding(src)
        embedded = self.dropout(src)
        # LSTM 输入为[len src, batch_size, emb dim], 每一个单词作为一个时间步, 每一个单词的特征大小为embedded 向量大小
        outputs, (hidden, cell) = self.rnn(embedded)

        # outputs = [len src, batch size, hid dim * n directions]
        # hidden = [n layers * n directions, batch size, hid dim]
        # cell = [n layers * n directions, batch size, hid dim]

        # 返回最后一个时间步的hidden state, cell state 作为学到的 context vector

        return hidden, cell
</code></pre>

<p>解码器构造</p>

<pre><code class="language-python">class Decoder(nn.Module):
    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):
        super().__init__()
        # 目标词汇表的大小, 最后的输出层为分类层, 输出属于词汇表中每一个单词的概率
        self.output_dim = output_dim
        # LSTM 每一个门的神经元个数
        self.hid_dim = hid_dim
        # LSTM 层数
        self.n_layers = n_layers

        # Embedding 初始化时指定词汇表的大小和需要得到的词向量大小
        # 前向传播时输入数据为该语句中每个单词在词汇表中的index,会根据index去查找
        self.embedding = nn.Embedding(output_dim, emb_dim)

        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)

        # 全连接层, 对每一个时间步的输出映射为词汇表中每一个词的概率
        self.fc_out = nn.Linear(hid_dim, output_dim)

        self.dropout = nn.Dropout(dropout)

    def forward(self, x, hidden, cell):
        # decoder 每1个batch只输入一个单词, 因此当前输入x shape=[batch_size]
        # 例: 当batch_size 为4时, 假如 x=[2,56,5,7], 表示batch[0] 输入单词在词汇表中的index为2（batch[0]... batch[3]即来自4个不同的句子）

        # 上一个时间步的状态输出
        # hidden = [n layers * n directions, batch size, hid dim]
        # cell = [n layers * n directions, batch size, hid dim]

        # 由于编码器每次的输入的时间步都为1, 故无法双向
        # hidden = [n layers, batch size, hid dim]
        # context = [n layers, batch size, hid dim]

        # x = [1, batch size]
        x = x.unsqueeze(0)
        
        # 得到当前目标单词在目标词汇表中的embedding 表示
        # embedded = [1, batch size, emb dim]
        embedded = self.dropout(self.embedding(x))

        # 解码器LSTM第一次调用时, 传入编码器最后的(hidden,cell)初始化解码器的(hidden, cell)
        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))
        
        # 由于编码器每次的输入的时间步都为1, 即序列长度 seq len 为1, 且无法双向
        # output = [seq len, batch size, hid dim * n directions]
        # hidden = [n layers * n directions, batch size, hid dim]
        # cell = [n layers * n directions, batch size, hid dim]

        # output = [1, batch size, hid dim]
        # hidden = [n layers, batch size, hid dim]
        # cell = [n layers, batch size, hid dim]
        
        # 得到当前预测的下一个单词分别属于词汇表中每一个单词的概率
        prediction = self.fc_out(output.squeeze(0))
        # prediction = [batch size, output dim]

        return prediction, hidden, cell
</code></pre>

<p>Seq2Seq模型</p>

<pre><code class="language-python">class Seq2Seq(nn.Module):
    def __init__(self, src_vocab_size, tag_vocab_size, enc_embed_dim, dec_embed_dim, hidden, layers, drop, device):
        super().__init__()
        &quot;&quot;&quot;
        src_vocab_size: 源词汇表大小
        tag_vocab_size: 目标词汇表大小
        enc_embed_dim: 编码器中的词向量维度
        dec_embed_dim: 解码器中的词向量维度
        hidden: LSTM 隐层神经元个数
        layers: LSTM 层数
        drop: dropout
        &quot;&quot;&quot;
        # 需要使用编码器的状态初始化解码器的状态, 因此二者神经元个数和层数必须一样
        self.encoder = Encoder(input_dim=src_vocab_size, emb_dim=enc_embed_dim, hid_dim=hidden, n_layers=layers, dropout=drop)
        self.decoder = Decoder(output_dim=tag_vocab_size, emb_dim=dec_embed_dim, hid_dim=hidden, n_layers=layers, dropout=drop)
        self.device = device

    def forward(self, src, tag, teacher_forcing_ratio=0.5):
        &quot;&quot;&quot;

        :param src: src = [src len, batch size] 填充到同样大小的源语句
        :param tag: tag = [tag len, batch size] 填充到同样大小的目标语句
        :param teacher_forcing_ratio: 使用teacher forcing的概率
        :return:
        &quot;&quot;&quot;

        batch_size = tag.shape[1]
        tag_len = tag.shape[0]
        tag_vocab_size = self.decoder.output_dim

        # 存储编码器预测输出 (目标语句的单词数, batch_size, 目标词汇表大小)
        outputs = torch.zeros(tag_len, batch_size, tag_vocab_size).to(self.device)

        # 编码器对源语句进行编码, 获取hidden, cell state 作为 context vector来初始化解码器的hidden, cell state
        hidden, cell = self.encoder(src)

        # 第一个输入解码器的为语句开始的标志 &lt;sos&gt;
        x = tag[0, :]

        # 根据目标语句的大小, 循环方式调用解码器, 每次解码一个词
        for t in range(1, tag_len):
            # 插入token, 前一个时间步的 hidden, cell states,
            # 输出预测, hidden, cell states
            output, hidden, cell = self.decoder(x, hidden, cell)

            # 保存预测输出
            outputs[t] = output

            # 决定是否使用 teacher forcing
            teacher_force = random.random() &lt; teacher_forcing_ratio

            # 获取当前预测的最高概率的token
            top1 = output.argmax(1)

            # 如果使用 teacher forcing, 使用实际的下一个词作为输入, 否则使用预测的作为下一个输入
            x = tag[t] if teacher_force else top1

        return outputs
</code></pre>

<p><em>注意: 解码器循环从1开始, 输出 outputs[0] 为0, 输入输出个数如下:</em></p>

<p>$$ tag= [&lt;sos&gt;, y_1, y_2, y_3, &lt;eos&gt;]$$
$$ outputs = [0, \hat  y _1, \hat y _2, \hat y _3, &lt;eos&gt;]$$</p>

<p>&lt;sos&gt; 为语句开始标志, &lt;eos&gt; 为语句结束标志. 所以计算损失的时候忽略掉第一项.</p>

<p><em>初窥NLP告一段落, 数据加载以及训练就是一些小的细节了, 具体移步<a href="http://localhost:8889/notebooks/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb">原链接</a>.</em></p>

<h2 id="ref">REF</h2>

<p><a href="http://localhost:8889/notebooks/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb">pytorch-seq2seq</a></p>

		</div>
		
	</article>
</main>



    <div class="post bg-white">
      <script src="https://utteranc.es/client.js"
            repo= "yl305237731/yl305237731.github.io"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>
    </div>

<div class="social-share"></div>
  <br/>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="Lin Yang avatar" src="/img/timg.gif" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About Lin Yang</span>
	</div>
	<div class="authorbox__description">
		ML, DL, CV....
	</div>
</div>




<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/post/pytorch_crnn%E5%AE%9E%E8%B7%B5/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Pytorch: CRNN 实践</p></a>
	</div>
</nav>

			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/post/seq2seq%E6%A8%A1%E5%9E%8B/">Seq2Seq模型: 从理论到实践</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/pytorch_crnn%E5%AE%9E%E8%B7%B5/">Pytorch: CRNN 实践</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84nms/">文本检测中的nms</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/yolov4/">YOLOv4: Optimal Speed and Accuracy of Object Detection论文解读</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8Biou%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E6%B1%87%E6%80%BB/">目标检测IOU评价指标汇总: GIOU, DIOU, CIOU</a></li>
		</ul>
	</div>
</div>
<div class="widget-categories widget">
	<h4 class="widget__title">Categories</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/categories/keras">Keras</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/leetcode">Leetcode</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/linux">Linux</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/tools">Tools</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e5%89%91%e6%8c%87offer">剑指offer</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e5%9b%be%e5%83%8f%e4%bf%ae%e5%a4%8d">图像修复</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e5%9b%be%e5%83%8f%e5%a2%9e%e5%bc%ba">图像增强</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e5%9b%be%e5%83%8f%e5%a4%84%e7%90%86">图像处理</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0">机器学习</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0">深度学习</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86">自然语言处理</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89">计算机视觉</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e8%ae%ba%e6%96%87%e9%98%85%e8%af%bb">论文阅读</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget-taglist__link widget__link btn" href="/tags/anchor" title="Anchor">Anchor</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/anchor-free" title="Anchor free">Anchor free</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/cbir" title="Cbir">Cbir</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/deeplab" title="Deeplab">Deeplab</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/densecrf" title="Densecrf">Densecrf</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/dlib" title="Dlib">Dlib</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/docker" title="Docker">Docker</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/facenet" title="Facenet">Facenet</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/fast-rcnn" title="Fast rcnn">Fast rcnn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/faster_rcnn" title="Faster rcnn">Faster rcnn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/fpn" title="Fpn">Fpn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/gan" title="Gan">Gan</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/gitlab" title="Gitlab">Gitlab</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/google_images_download" title="Google images download">Google images download</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/hadoop%e5%91%bd%e4%bb%a4" title="Hadoop命令">Hadoop命令</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/hive" title="Hive">Hive</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/hrnet" title="Hrnet">Hrnet</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/imagenet" title="Imagenet">Imagenet</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/inception" title="Inception">Inception</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/iterm2" title="Iterm2">Iterm2</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/keras" title="Keras">Keras</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/knn" title="Knn">Knn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/leetcode" title="Leetcode">Leetcode</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/libsvm" title="Libsvm">Libsvm</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/linux" title="Linux">Linux</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/lstm" title="Lstm">Lstm</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/maccmd" title="Maccmd">Maccmd</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/markdown%e8%af%ad%e6%b3%95" title="Markdown语法">Markdown语法</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/mnist%e8%bd%ac%e5%9b%be%e7%89%87" title="Mnist转图片">Mnist转图片</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/numpy-gpu%e5%8a%a0%e9%80%9f" title="Numpy gpu加速">Numpy gpu加速</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ocr" title="Ocr">Ocr</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ohem" title="Ohem">Ohem</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pandas" title="Pandas">Pandas</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/progan" title="Progan">Progan</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/psnr" title="Psnr">Psnr</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pyplot%e6%96%87%e6%a1%a3" title="Pyplot文档">Pyplot文档</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/python" title="Python">Python</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pytorch" title="Pytorch">Pytorch</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ransac" title="Ransac">Ransac</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/rcnn" title="Rcnn">Rcnn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/roialign" title="Roialign">Roialign</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/se-net" title="Se net">Se net</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/separable-convolutions" title="Separable convolutions">Separable convolutions</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/simplehttpserver" title="Simplehttpserver">Simplehttpserver</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/sppnet" title="Sppnet">Sppnet</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ssd" title="Ssd">Ssd</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ubuntu" title="Ubuntu">Ubuntu</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/video-object-segementation" title="Video object segementation">Video object segementation</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/yolo" title="Yolo">Yolo</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/yolo_v3" title="Yolo v3">Yolo v3</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e4%ba%8c%e5%88%86%e7%b1%bb" title="二分类">二分类</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e4%ba%ba%e8%84%b8%e6%a3%80%e6%b5%8b" title="人脸检测">人脸检测</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%88%86%e5%89%b2" title="分割">分割</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%8e%8b%e7%bc%a9%e5%91%bd%e4%bb%a4" title="压缩命令">压缩命令</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%9b%9b%e9%a2%86%e5%9f%9f%e8%bf%9e%e9%80%9a%e6%a0%87%e8%ae%b0" title="四领域连通标记">四领域连通标记</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%9b%be%e5%83%8f%e5%8e%bb%e9%9b%be" title="图像去雾">图像去雾</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%a4%9a%e6%a0%87%e7%ad%be%e5%88%86%e7%b1%bb" title="多标签分类">多标签分类</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%ad%aa%e7%94%9f%e7%bd%91%e7%bb%9c" title="孪生网络">孪生网络</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e6%95%b0%e6%8d%ae%e5%8a%a0%e8%bd%bd" title="数据加载">数据加载</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba" title="数据增强">数据增强</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e6%9c%80%e5%b0%8f%e4%ba%8c%e4%b9%98%e6%b3%95" title="最小二乘法">最小二乘法</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e6%a8%a1%e7%89%88%e5%8c%b9%e9%85%8d" title="模版匹配">模版匹配</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0" title="深度学习">深度学习</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e7%9b%ae%e6%a0%87%e5%88%86%e5%89%b2" title="目标分割">目标分割</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b" title="目标检测">目标检测</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e7%9b%b8%e5%85%b3" title="相关">相关</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e8%b6%85%e5%88%86%e8%be%a8%e7%8e%87%e9%87%8d%e5%bb%ba" title="超分辨率重建">超分辨率重建</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e8%b7%b3%e6%9d%bf%e6%9c%ba" title="跳板机">跳板机</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e8%be%b9%e7%bc%98%e6%a3%80%e6%b5%8b" title="边缘检测">边缘检测</a>
	</div>
</div>
<div class="widget-social widget">
	<h4 class="widget-social__title widget__title">Social</h4>
	<div class="widget-social__content widget__content">
		<div class="widget-social__item widget__item">
			<a class="widget-social__link widget__link btn" title="GitHub" rel="noopener noreferrer" href="https://github.com/yl305237731" target="_blank">
				<svg class="widget-social__link-icon icon-github" viewBox="0 0 384 374" width="24" height="24" fill="#fff"><path d="m192 0c-106.1 0-192 85.8-192 191.7 0 84.7 55 156.6 131.3 181.9 9.6 1.8 13.1-4.2 13.1-9.2 0-4.6-.2-16.6-.3-32.6-53.4 11.6-64.7-25.7-64.7-25.7-8.7-22.1-21.3-28-21.3-28-17.4-11.9 1.3-11.6 1.3-11.6 19.3 1.4 29.4 19.8 29.4 19.8 17.1 29.3 44.9 20.8 55.9 15.9 1.7-12.4 6.7-20.8 12.2-25.6-42.6-4.8-87.5-21.3-87.5-94.8 0-20.9 7.5-38 19.8-51.4-2-4.9-8.6-24.3 1.9-50.7 0 0 16.1-5.2 52.8 19.7 15.3-4.2 31.7-6.4 48.1-6.5 16.3.1 32.7 2.2 48.1 6.5 36.7-24.8 52.8-19.7 52.8-19.7 10.5 26.4 3.9 45.9 1.9 50.7 12.3 13.4 19.7 30.5 19.7 51.4 0 73.7-44.9 89.9-87.7 94.6 6.9 5.9 13 17.6 13 35.5 0 25.6-.2 46.3-.2 52.6 0 5.1 3.5 11.1 13.2 9.2 76.2-25.5 131.2-97.3 131.2-182 0-105.9-86-191.7-192-191.7z"/></svg>
				<span>GitHub</span>
			</a>
		</div>
		<div class="widget-social__item widget__item">
			<a class="widget-social__link widget__link btn" title="Email" href="mailto:16120438@bjtu.edu.cn">
				<svg class="widget-social__link-icon icon-mail" viewBox="0 0 416 288" width="24" height="24" fill="#fff"><path d="m0 16v256 16h16 384 16v-16-256-16h-16-384-16zm347 16-139 92.5-139-92.5zm-148 125.5 9 5.5 9-5.5 167-111.5v210h-352v-210z"/></svg>
				<span>16120438@bjtu.edu.cn</span>
			</a>
		</div>
	</div>
</div>
<div>
<a href="https://www.vultr.com/?ref=8356490"><img src="https://www.vultr.com/media/banners/banner_300x250.png" width="300" height="250"></a>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2020 fly away, chase dream.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/kingfsen/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script async src="/js/highlight.js"></script><script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style> 
  <script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https'){
   bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


 
  
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<script type="text/javascript">
    (function(){
        $("pre code").parent().addClass("line-numbers")
    }())
</script>

</body>
</html>