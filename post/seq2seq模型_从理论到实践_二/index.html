<!DOCTYPE html>
<html class="no-js" lang="zh-cn">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Seq2Seq模型: 从理论到实践(二) - fly away, chase dream</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<script type="text/javascript" src="/js/jquery.min.js"></script>
	
	<meta name="description" content="">
	<meta name="generator" content="Hugo 0.57.2" />
	<meta property="og:title" content="Seq2Seq模型: 从理论到实践(二)" />
<meta property="og:description" content="本文图片、代码来源于pytorch-se12seq, 加深个人理解 在上文中使用的编码器-解码器结构如下: （一）信息压缩问题 对于上诉的解码器而言" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/seq2seq%E6%A8%A1%E5%9E%8B_%E4%BB%8E%E7%90%86%E8%AE%BA%E5%88%B0%E5%AE%9E%E8%B7%B5_%E4%BA%8C/" />
<meta property="article:published_time" content="2020-05-02T17:03:16+08:00" />
<meta property="article:modified_time" content="2020-05-02T17:03:16+08:00" />

	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">	
	<link rel="stylesheet" type="text/css" href="/css/highlight.css">
	
	
	<link rel="stylesheet" href="/css/share.min.css">
	<script src="/js/social-share.min.js"></script>
	<script src="/js/qrcode.js"></script>
	
	<link rel="stylesheet" href="/css/custom.css">
	<link rel="shortcut icon" href="/favicon.ico">
		
	
    
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-3547912397637948",
      enable_page_level_ads: true
    });
  </script>

	
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/" title="fly away, chase dream" rel="home">
			<div class="logo__title">fly away, chase dream</div>			
				<div class="logo__tagline">ML、CV、Image process, NLP beginning</div> 
			</a>
			
			<div class="float_right"><div class="social-share"></div>
  <br/></div>
			
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/about/">about</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/">blog</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/leetcode/">leetcode</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/life/">life📚</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/links/">links</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/wiki/">wiki</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="container">
      <a href="https://www.vultr.com/?ref=8356511-4F"><img src="https://www.vultr.com/media/banners/banner_728x90.png" width="800" height="90"></a>
		</div>
		<hr/>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Seq2Seq模型: 从理论到实践(二)</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2020-05-02T17:03:16">2020-05-02</time>
</div>

<div class="meta__item-categories meta__item">
	<svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
	<span class="meta__text"><a class="meta__link" href="/categories/%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86" rel="category">自然语言处理</a></span>
</div>
</div>
		</header>
<div class="content post__content clearfix">
			

<p><em>本文图片、代码来源于<a href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/2%20-%20Learning%20Phrase%20Representations%20using%20RNN%20Encoder-Decoder%20for%20Statistical%20Machine%20Translation.ipynb">pytorch-se12seq</a>, 加深个人理解</em></p>

<p>在<a href="http://note4lin.top/post/seq2seq%E6%A8%A1%E5%9E%8B/">上文</a>中使用的编码器-解码器结构如下:</p>

<div align="center"><img src="/img/seq2seq/2.jpg" width="600" height="600"></div>

<h2 id="一-信息压缩问题">（一）信息压缩问题</h2>

<p>对于上诉的解码器而言, 只有第一个时间步时使用的是初始的 context vector, 对之后时间步的解码完全依赖于上一个时间步的隐状态, 这存在信息压缩, 我们希望每一个时间步都能从原始的context vector中提取信息.</p>

<div align="center"><img src="/img/seq2seq/4.jpg" width="400" height="600"></div>

<p>新的解码器结构如上图, 每一个时间步, context vector与embedding vector一起输入RNN结构中, 同时最终的分类层输入为当前的隐状态、embedding vector和 context vector.</p>

<p>采用GRU作为RNN单元实现的Decoder如下:</p>

<pre><code class="language-python">class Decoder(nn.Module):
    def __init__(self, output_dim, emb_dim, hid_dim, dropout):
        &quot;&quot;&quot;
        :param output_dim: 目标词汇表的大小
        :param emb_dim: 词向量大小
        :param hid_dim: GRU 隐层神经元个数
        :param dropout: 
        &quot;&quot;&quot;
        super().__init__()
        self.hid_dim = hid_dim
        self.output_dim = output_dim
        
        self.embedding = nn.Embedding(output_dim, emb_dim)
        
        # context vector 与 hid_dim 大小一样
        # GRU 的输入为 concat [context vector, embedding vector]
        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)
        # 分类层输入为 concat [context vector, embedding vector, hidden dim]
        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x, hidden, context):
        &quot;&quot;&quot;
        
        :param x: [batch_size] 
        :param hidden: 
        :param context: 
        :return: 
        &quot;&quot;&quot;
        #  x = [1, batch size]
        x = x.unsqueeze(0)
        
        # 目标token embedding
        # embedded = [1, batch size, emb dim]
        embedded = self.dropout(self.embedding(x))
        
        # 将embed vector 与 context concat
        # emb_con = [1, batch size, emb dim + hid dim]
        emb_con = torch.cat((embedded, context), dim = 2)
        
        # GRU 输出  
        output, hidden = self.rnn(emb_con, hidden)
        
        # cat 当前的隐状态、embedding vector和 context vector
        # output = [batch size, emb dim + hid dim * 2]
        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), 
                           dim = 1)
        
        # 分类
        # prediction = [batch size, output dim]
        prediction = self.fc_out(output)
        
        return prediction, hidden

</code></pre>

<h2 id="二-attention-seq2seq">（二） Attention seq2seq</h2>

<p>上面的模型在一定程度上解决了信息压缩的问题, 存在的问题是：在将输入句子编码为定长的向量后，每次解码时使用context vector，而context vector 中每个词的权重一样。比如对于翻译而言，输出的一个词往往对应于输出的一个或多个词，每次都用整个语句是不合理的。因此，attention的思想就是对源语句的每个词在每次解码时赋予不同的权重，权重越大，贡献越大.</p>

<p>在翻译中的实现: 参照<a href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb">3 - Neural Machine Translation by Jointly Learning to Align and Translate</a></p>

<p>使用GRU为解码器，解码器 t-1 时间步的hidden state 为，$s _{t-1}$，编码器在整个序列上的 $h_t$ 构成的 $H$. (LSTM、GRU 返回值详见源码, 简单说第一项为每个时间步的hidden state, 第二项为最后一个时间步的hidden state). 解码的每一个时间步，attention 层输出一个attention vector  $a _t$，$a_t$中每一个元素值在0-1之间，且 $sum(a_t)=1$.</p>

<p>直观地说，attention层利用我们迄今为止解码的内容 $s _{t-1}$，以及所有我们已经编码的内容 $H$，产生一个向量 $a _t$，代表源语句中我们最应该注意的单词，以便正确预测下一个要解码的单词。</p>

<p>$$a_t=attn(s _{t-1}, H)$$</p>

<p>这可以被认为是计算每个编码器隐藏状态“匹配”上一个解码器隐藏状态的程度。图示如下, 计算第一个attention vector, 由编码器在整个序列上的hidden state 和解码器的 $s_0 =z$计算attention vector $a_t$</p>

<div align="center"><img src="/img/seq2seq/5.jpg" width="600" height="500"></div>

<p>那么 seq2seq 模型结构为:</p>

<div align="center"><img src="/img/seq2seq/6.jpg" width="600" height="600"></div>

<p>梳理带 attention 的seq2seq流程:</p>

<ul>
<li>编码器部分对输入序列进行编码，输出每个时间步的hidden state作为attention 需要的输入和最后一个时间步的状态作为context vector</li>
<li>解码器的每一个时间步, 首先根据上一个时间步得到的hidden state 和编码器所有的hidden state $W$ 得到attention的权值，将 $W$ 加权后和embedded vector输入解码器.</li>
</ul>

<p>对于seq2seq 模型的attention模型可按以下图理解:</p>

<p><em>在解码阶段，每一次都会根据当前的hidden state 与输入序列的所有hidden state计算attention值，本质是为了得到当前的hidden state 与输入序列哪些最相关，即 $ s _{t-1} $ 为一个query，去源语句的hidden state 中去查找哪些与它最相关，key, value 是编码器每一个时间步的hidden state，使用 query与每个key计算匹配度，再乘以value，即得到加权的value&ndash;attention</em></p>

<div align="center"><img src="/img/seq2seq/7.jpg" width="600"></div>

<p>模型通过Q和K的匹配计算出权重，再结合V得到输出, attention 可表示为下式:</p>

<p>$$Attention(Q,K,V)=softmax(match(Q,K)) * V$$</p>

<h2 id="ref">REF</h2>

<p><a href="https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb">参考代码</a></p>

		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/nlp/" rel="tag">nlp</a></li>
	</ul>
</div>
	</article>
</main>



    <div class="post bg-white">
      <script src="https://utteranc.es/client.js"
            repo= "yl305237731/yl305237731.github.io"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>
    </div>

<div class="social-share"></div>
  <br/>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="Lin Yang avatar" src="/img/timg.gif" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About Lin Yang</span>
	</div>
	<div class="authorbox__description">
		ML, DL, CV....
	</div>
</div>




<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/post/seq2seq%E6%A8%A1%E5%9E%8B/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Seq2Seq模型: 从理论到实践(一)</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/post/image_caption_1/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">Image Caption模型</p></a>
	</div>
</nav>

			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/post/yolo_v5%E4%BB%8E%E7%90%86%E8%AE%BA%E5%88%B0%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2%E5%AE%9E%E8%B7%B5/">Yolo-v5从代码到服务部署实践</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/%E4%BD%BF%E7%94%A8nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/">使用nginx实现服务反向代理实现负载均衡</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/cspnet/">CSPNet</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/cbam%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9D%97/">CBAM注意力模块: Convolutional Block Attention Module</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/image_caption_1/">Image Caption模型</a></li>
		</ul>
	</div>
</div>
<div class="widget-categories widget">
	<h4 class="widget__title">Categories</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/categories/keras">Keras</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/leetcode">Leetcode</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/linux">Linux</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/tools">Tools</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e5%89%91%e6%8c%87offer">剑指offer</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e5%9b%be%e5%83%8f%e4%bf%ae%e5%a4%8d">图像修复</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e5%9b%be%e5%83%8f%e5%a2%9e%e5%bc%ba">图像增强</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e5%9b%be%e5%83%8f%e5%a4%84%e7%90%86">图像处理</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0">机器学习</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0">深度学习</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86">自然语言处理</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89">计算机视觉</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e8%ae%ba%e6%96%87%e9%98%85%e8%af%bb">论文阅读</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget-taglist__link widget__link btn" href="/tags/anchor" title="Anchor">Anchor</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/anchor-free" title="Anchor free">Anchor free</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/cbam" title="Cbam">Cbam</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/cbir" title="Cbir">Cbir</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/cspnet" title="Cspnet">Cspnet</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/deeplab" title="Deeplab">Deeplab</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/densecrf" title="Densecrf">Densecrf</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/dlib" title="Dlib">Dlib</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/docker" title="Docker">Docker</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/facenet" title="Facenet">Facenet</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/fast-rcnn" title="Fast rcnn">Fast rcnn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/faster_rcnn" title="Faster rcnn">Faster rcnn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/fpn" title="Fpn">Fpn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/gan" title="Gan">Gan</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/gitlab" title="Gitlab">Gitlab</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/google_images_download" title="Google images download">Google images download</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/hadoop%e5%91%bd%e4%bb%a4" title="Hadoop命令">Hadoop命令</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/hive" title="Hive">Hive</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/hrnet" title="Hrnet">Hrnet</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/image-caption" title="Image caption">Image caption</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/imagenet" title="Imagenet">Imagenet</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/inception" title="Inception">Inception</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/iterm2" title="Iterm2">Iterm2</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/keras" title="Keras">Keras</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/knn" title="Knn">Knn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/leetcode" title="Leetcode">Leetcode</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/libsvm" title="Libsvm">Libsvm</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/linux" title="Linux">Linux</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/lstm" title="Lstm">Lstm</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/maccmd" title="Maccmd">Maccmd</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/markdown%e8%af%ad%e6%b3%95" title="Markdown语法">Markdown语法</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/mnist%e8%bd%ac%e5%9b%be%e7%89%87" title="Mnist转图片">Mnist转图片</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/nlp" title="Nlp">Nlp</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/numpy-gpu%e5%8a%a0%e9%80%9f" title="Numpy gpu加速">Numpy gpu加速</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ocr" title="Ocr">Ocr</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ohem" title="Ohem">Ohem</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pandas" title="Pandas">Pandas</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/progan" title="Progan">Progan</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/psnr" title="Psnr">Psnr</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pyplot%e6%96%87%e6%a1%a3" title="Pyplot文档">Pyplot文档</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/python" title="Python">Python</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pytorch" title="Pytorch">Pytorch</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ransac" title="Ransac">Ransac</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/rcnn" title="Rcnn">Rcnn</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/roialign" title="Roialign">Roialign</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/se-net" title="Se net">Se net</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/separable-convolutions" title="Separable convolutions">Separable convolutions</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/simplehttpserver" title="Simplehttpserver">Simplehttpserver</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/sppnet" title="Sppnet">Sppnet</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ssd" title="Ssd">Ssd</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ubuntu" title="Ubuntu">Ubuntu</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/video-object-segementation" title="Video object segementation">Video object segementation</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/yolo" title="Yolo">Yolo</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/yolo_v3" title="Yolo v3">Yolo v3</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/yolo_v5" title="Yolo v5">Yolo v5</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e4%ba%8c%e5%88%86%e7%b1%bb" title="二分类">二分类</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e4%ba%ba%e8%84%b8%e6%a3%80%e6%b5%8b" title="人脸检测">人脸检测</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%88%86%e5%89%b2" title="分割">分割</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%88%86%e5%b8%83%e5%bc%8f%e7%ae%97%e6%b3%95%e6%9c%8d%e5%8a%a1" title="分布式算法服务">分布式算法服务</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%8e%8b%e7%bc%a9%e5%91%bd%e4%bb%a4" title="压缩命令">压缩命令</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%9b%9b%e9%a2%86%e5%9f%9f%e8%bf%9e%e9%80%9a%e6%a0%87%e8%ae%b0" title="四领域连通标记">四领域连通标记</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%9b%be%e5%83%8f%e5%8e%bb%e9%9b%be" title="图像去雾">图像去雾</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%a4%9a%e6%a0%87%e7%ad%be%e5%88%86%e7%b1%bb" title="多标签分类">多标签分类</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e5%ad%aa%e7%94%9f%e7%bd%91%e7%bb%9c" title="孪生网络">孪生网络</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e6%95%b0%e6%8d%ae%e5%8a%a0%e8%bd%bd" title="数据加载">数据加载</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba" title="数据增强">数据增强</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e6%9c%80%e5%b0%8f%e4%ba%8c%e4%b9%98%e6%b3%95" title="最小二乘法">最小二乘法</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e6%a8%a1%e7%89%88%e5%8c%b9%e9%85%8d" title="模版匹配">模版匹配</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0" title="深度学习">深度学习</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e7%9b%ae%e6%a0%87%e5%88%86%e5%89%b2" title="目标分割">目标分割</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b" title="目标检测">目标检测</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e7%9b%b8%e5%85%b3" title="相关">相关</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e8%b6%85%e5%88%86%e8%be%a8%e7%8e%87%e9%87%8d%e5%bb%ba" title="超分辨率重建">超分辨率重建</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e8%b7%b3%e6%9d%bf%e6%9c%ba" title="跳板机">跳板机</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%e8%be%b9%e7%bc%98%e6%a3%80%e6%b5%8b" title="边缘检测">边缘检测</a>
	</div>
</div>
<div class="widget-social widget">
	<h4 class="widget-social__title widget__title">Social</h4>
	<div class="widget-social__content widget__content">
		<div class="widget-social__item widget__item">
			<a class="widget-social__link widget__link btn" title="GitHub" rel="noopener noreferrer" href="https://github.com/yl305237731" target="_blank">
				<svg class="widget-social__link-icon icon-github" viewBox="0 0 384 374" width="24" height="24" fill="#fff"><path d="m192 0c-106.1 0-192 85.8-192 191.7 0 84.7 55 156.6 131.3 181.9 9.6 1.8 13.1-4.2 13.1-9.2 0-4.6-.2-16.6-.3-32.6-53.4 11.6-64.7-25.7-64.7-25.7-8.7-22.1-21.3-28-21.3-28-17.4-11.9 1.3-11.6 1.3-11.6 19.3 1.4 29.4 19.8 29.4 19.8 17.1 29.3 44.9 20.8 55.9 15.9 1.7-12.4 6.7-20.8 12.2-25.6-42.6-4.8-87.5-21.3-87.5-94.8 0-20.9 7.5-38 19.8-51.4-2-4.9-8.6-24.3 1.9-50.7 0 0 16.1-5.2 52.8 19.7 15.3-4.2 31.7-6.4 48.1-6.5 16.3.1 32.7 2.2 48.1 6.5 36.7-24.8 52.8-19.7 52.8-19.7 10.5 26.4 3.9 45.9 1.9 50.7 12.3 13.4 19.7 30.5 19.7 51.4 0 73.7-44.9 89.9-87.7 94.6 6.9 5.9 13 17.6 13 35.5 0 25.6-.2 46.3-.2 52.6 0 5.1 3.5 11.1 13.2 9.2 76.2-25.5 131.2-97.3 131.2-182 0-105.9-86-191.7-192-191.7z"/></svg>
				<span>GitHub</span>
			</a>
		</div>
		<div class="widget-social__item widget__item">
			<a class="widget-social__link widget__link btn" title="Email" href="mailto:16120438@bjtu.edu.cn">
				<svg class="widget-social__link-icon icon-mail" viewBox="0 0 416 288" width="24" height="24" fill="#fff"><path d="m0 16v256 16h16 384 16v-16-256-16h-16-384-16zm347 16-139 92.5-139-92.5zm-148 125.5 9 5.5 9-5.5 167-111.5v210h-352v-210z"/></svg>
				<span>16120438@bjtu.edu.cn</span>
			</a>
		</div>
	</div>
</div>
<div>
<a href="https://www.vultr.com/?ref=8356490"><img src="https://www.vultr.com/media/banners/banner_300x250.png" width="300" height="250"></a>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 fly away, chase dream.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/kingfsen/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script async src="/js/highlight.js"></script><script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style> 
  <script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https'){
   bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


 
  
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<script type="text/javascript">
    (function(){
        $("pre code").parent().addClass("line-numbers")
    }())
</script>

</body>
</html>